{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOwFfDvWlx2isbnd2/DoT7l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sandeephm/GoogleColab-codes/blob/master/CUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G-MjA167HBL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "497ae2ef-3978-4796-baf7-f5bb76efd54d"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-9bysd5z7\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-9bysd5z7\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=a64a6042edde1a3e8215bd8b362baea32a5a22090e1a9d10ead20d6296012266\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g88dlb0p/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyG-G10m7hV0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "50ffd086-9291-4be3-82ac-9d0b153fb0ce"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dV-PHEC8hBS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b8a10673-1ba7-4903-df4f-8f06612a3234"
      },
      "source": [
        "%%cu \n",
        "#include <iostream> \n",
        "int main() \n",
        "{ \n",
        "    std::cout << \"Welcome To GeeksforGeeks\\n\"; \n",
        "    return 0; \n",
        "} "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome To GeeksforGeeks\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahP6ldcN7ldC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e4511e86-7523-4444-d227-d9e28e5bb8d2"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "*c = *a + *b;\n",
        "}\n",
        "int main() {\n",
        "int a, b, c;\n",
        "// host copies of variables a, b & c\n",
        "int *d_a, *d_b, *d_c;\n",
        "// device copies of variables a, b & c\n",
        "int size = sizeof(int);\n",
        "// Allocate space for device copies of a, b, c\n",
        "cudaMalloc((void **)&d_a, size);\n",
        "cudaMalloc((void **)&d_b, size);\n",
        "cudaMalloc((void **)&d_c, size);\n",
        "// Setup input values  \n",
        "c = 0;\n",
        "a = 3;\n",
        "b = 5;\n",
        "// Copy inputs to device\n",
        "cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "// Launch add() kernel on GPU\n",
        "add<<<1,1>>>(d_a, d_b, d_c);\n",
        "// Copy result back to host\n",
        "cudaError err = cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "  if(err!=cudaSuccess) {\n",
        "      printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "printf(\"result is %d\\n\",c);\n",
        "// Cleanup\n",
        "cudaFree(d_a);\n",
        "cudaFree(d_b);\n",
        "cudaFree(d_c);\n",
        "return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result is 8\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2yYidR6993M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "59ec36dc-467b-4319-826a-d4208e3cffb8"
      },
      "source": [
        "%%cu \n",
        "#include <cstdio> \n",
        "#include <iostream> \n",
        "  \n",
        "using namespace std; \n",
        "  \n",
        "__global__ void maxi(int* a, int* b, int n) \n",
        "{ \n",
        "    int block = 256 * blockIdx.x; \n",
        "    int max = 0; \n",
        "  \n",
        "    for (int i = block; i < min(256 + block, n); i++) { \n",
        "  \n",
        "        if (max < a[i]) { \n",
        "            max = a[i]; \n",
        "        } \n",
        "    } \n",
        "    b[blockIdx.x] = max; \n",
        "} \n",
        "  \n",
        "int main() \n",
        "{ \n",
        "  \n",
        "    int n; \n",
        "    n = 3 >> 2; \n",
        "    int a[n]; \n",
        "  \n",
        "    for (int i = 0; i < n; i++) { \n",
        "        a[i] = rand() % n; \n",
        "        cout << a[i] << \"\\t\"; \n",
        "    } \n",
        "  \n",
        "    cudaEvent_t start, end; \n",
        "    int *ad, *bd; \n",
        "    int size = n * sizeof(int); \n",
        "    cudaMalloc(&ad, size); \n",
        "    cudaMemcpy(ad, a, size, cudaMemcpyHostToDevice); \n",
        "    int grids = ceil(n * 1.0f / 256.0f); \n",
        "    cudaMalloc(&bd, grids * sizeof(int)); \n",
        "  \n",
        "    dim3 grid(grids, 1); \n",
        "    dim3 block(1, 1); \n",
        "  \n",
        "    cudaEventCreate(&start); \n",
        "    cudaEventCreate(&end); \n",
        "    cudaEventRecord(start); \n",
        "  \n",
        "    while (n > 1) { \n",
        "        maxi<<<grids, block>>>(ad, bd, n); \n",
        "        n = ceil(n * 1.0f / 256.0f); \n",
        "        cudaMemcpy(ad, bd, n * sizeof(int), cudaMemcpyDeviceToDevice); \n",
        "    } \n",
        "  \n",
        "    cudaEventRecord(end); \n",
        "    cudaEventSynchronize(end); \n",
        "  \n",
        "    float time = 0; \n",
        "    cudaEventElapsedTime(&time, start, end); \n",
        "  \n",
        "    int ans[2]; \n",
        "    cudaMemcpy(ans, ad, 4, cudaMemcpyDeviceToHost); \n",
        "  \n",
        "    cout << \"The maximum element is : \" << ans[0] << endl; \n",
        "  \n",
        "    cout << \"The time required : \"; \n",
        "    cout << time << endl; \n",
        "} "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The maximum element is : 2015486880\n",
            "The time required : 0.003328\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTASu9EhBUan",
        "colab_type": "text"
      },
      "source": [
        "Hello World Program in CUDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzAKK37XBX4p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "00b64faf-000a-4fe9-8ff8-c6dbd439f04e"
      },
      "source": [
        "%%cu\n",
        "#include <cstdio>\n",
        "#include \"cuda.h\"\n",
        "\n",
        "void CPUFunction()\n",
        "{\n",
        "  printf(\"Runs on the CPU.\\n\");\n",
        "}\n",
        "\n",
        "__global__\n",
        "void GPUFunction()\n",
        "{\n",
        "  printf(\"Runs on the GPU.\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  CPUFunction();\n",
        "\n",
        "  GPUFunction<<<1, 1>>>();\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  return EXIT_SUCCESS;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Runs on the CPU.\n",
            "Runs on the GPU.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR2P4CBnB9RV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "48e2f77a-3a31-4b38-e163-2a639005847f"
      },
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "// Kernel function to add the elements of two arrays\n",
        "__global__\n",
        "void add(int n, float *x, float *y)\n",
        "{\n",
        "  for (int i = 0; i < n; i++)\n",
        "    y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  int N = 1<<20;\n",
        "  float *x, *y;\n",
        "\n",
        "  // Allocate Unified Memory – accessible from CPU or GPU\n",
        "  cudaMallocManaged(&x, N*sizeof(float));\n",
        "  cudaMallocManaged(&y, N*sizeof(float));\n",
        "\n",
        "  // initialize x and y arrays on the host\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    x[i] = 1.0f;\n",
        "    y[i] = 2.0f;\n",
        "  }\n",
        "\n",
        "  // Run kernel on 1M elements on the GPU\n",
        "  add<<<1, 1>>>(N, x, y);\n",
        "\n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Check for errors (all values should be 3.0f)\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < N; i++)\n",
        "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
        "  std::cout << \"Max error: \" << maxError << std::endl;\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(x);\n",
        "  cudaFree(y);\n",
        "  \n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max error: 0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eMqW9YcLiAL",
        "colab_type": "text"
      },
      "source": [
        "Dynamic Memmory Allocation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3NmUlaWLl5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad107207-f059-4cab-f0d5-5bb4d9150e07"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void dynamicReverse(int *d, int n)\n",
        "{\n",
        "  // Dynamic shared memory\t\n",
        "  extern __shared__ int s[];\n",
        "  int t = threadIdx.x;\n",
        "  int tr = n-t-1;\n",
        "  s[t] = d[t];\n",
        "  __syncthreads();\n",
        "  d[t] = s[tr];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  const int n = 64;\n",
        "  int a[n], r[n], d[n];\n",
        "\n",
        "  for (int i = 0; i < n; i++) {\n",
        "    a[i] = i;\n",
        "    r[i] = n-i-1;\n",
        "    d[i] = 0;\n",
        "  }\n",
        "\n",
        "  int *d_d;\n",
        "  cudaMalloc(&d_d, n * sizeof(int)); \n",
        "\n",
        "  // run dynamic shared memory version\n",
        "  cudaMemcpy(d_d, a, n*sizeof(int), cudaMemcpyHostToDevice);\n",
        "  dynamicReverse<<<1,n,n*sizeof(int)>>>(d_d, n);\n",
        "  cudaMemcpy(d, d_d, n * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "  for (int i = 0; i < n; i++) \n",
        "    if (d[i] != r[i]) printf(\"Error: d[%d]!=r[%d] (%d, %d)n\", i, i, d[i], r[i]);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJDVVU0FPBSC",
        "colab_type": "text"
      },
      "source": [
        "Run Hello 5 times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFVVwIGiMjWl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "307a6f9e-711e-4a0e-9ef3-79045761f1b5"
      },
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include \"cuda.h\"\n",
        "\n",
        "void helloCPU()\n",
        "{\n",
        "  std::cout<<\"Hello from CPU.\\n\";\n",
        "}\n",
        "\n",
        "__global__ void helloGPU()\n",
        "{\n",
        "  printf(\"Hello also from GPU.\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "  helloCPU();\n",
        "  helloGPU<<<1,5>>>();\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  return EXIT_SUCCESS;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello from CPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oudZhusPGtb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "966e3925-3789-4ce6-f75a-263adf2e0ed3"
      },
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include \"cuda.h\"\n",
        "\n",
        "void helloCPU()\n",
        "{\n",
        "  std::cout<<\"Hello from CPU.\\n\";\n",
        "}\n",
        "\n",
        "__global__ void helloGPU()\n",
        "{\n",
        "  printf(\"Hello also from GPU.\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "  helloCPU();\n",
        "  helloGPU<<<5,5>>>();\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  return EXIT_SUCCESS;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello from CPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "Hello also from GPU.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etf01rloQI3P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fb8ee89f-47ab-42cd-c953-e8797f96f2ec"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include \"cuda.h\"\n",
        "\n",
        "__global__ void printSuccessForCorrectExecutionConfiguration()\n",
        "{\n",
        "  if (threadIdx.x == 1023 && blockIdx.x == 255)\n",
        "  {\n",
        "    printf(\"Success!\\n\");\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "  printSuccessForCorrectExecutionConfiguration<<<256,1024>>>();\n",
        "  cudaDeviceSynchronize();\n",
        "  return EXIT_SUCCESS;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWOb-_S0SSih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "779a0114-b382-4bb9-fd79-f11f1132fe34"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include \"cuda.h\"\n",
        "__global__ void loop(int N)\n",
        "{\n",
        "  for (int i = 0; i < N; ++i)\n",
        "  {\n",
        "    printf(\"This is iteration number %d\\n\", i);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  /*\n",
        "   * When refactoring 'loop' to launch as a kernel, be sure\n",
        "   * to use the execution configuration to control how many\n",
        "   * \"iterations\" to perform.\n",
        "   *\n",
        "   * Use 1 block of threads.\n",
        "   */\n",
        "\n",
        "  int N = 10;\n",
        "  loop<<<1,3>>>(N);\n",
        "  cudaDeviceSynchronize();\n",
        "  return EXIT_SUCCESS;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is iteration number 0\n",
            "This is iteration number 0\n",
            "This is iteration number 0\n",
            "This is iteration number 1\n",
            "This is iteration number 1\n",
            "This is iteration number 1\n",
            "This is iteration number 2\n",
            "This is iteration number 2\n",
            "This is iteration number 2\n",
            "This is iteration number 3\n",
            "This is iteration number 3\n",
            "This is iteration number 3\n",
            "This is iteration number 4\n",
            "This is iteration number 4\n",
            "This is iteration number 4\n",
            "This is iteration number 5\n",
            "This is iteration number 5\n",
            "This is iteration number 5\n",
            "This is iteration number 6\n",
            "This is iteration number 6\n",
            "This is iteration number 6\n",
            "This is iteration number 7\n",
            "This is iteration number 7\n",
            "This is iteration number 7\n",
            "This is iteration number 8\n",
            "This is iteration number 8\n",
            "This is iteration number 8\n",
            "This is iteration number 9\n",
            "This is iteration number 9\n",
            "This is iteration number 9\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igIS0k8nTJXe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4584c21b-adef-4ad4-a3dd-f965bb596782"
      },
      "source": [
        "%%cu\n",
        "#include <cstdio>\n",
        "\n",
        "/*\n",
        " * Initialize array values on the host.\n",
        " */\n",
        "\n",
        "//Function to initialize an array\n",
        "__global__ void init(int *a, int N)\n",
        "{\n",
        "  for (int i = 0; i < N; ++i) {\n",
        "    a[i] = i;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Double elements in parallel on the GPU.\n",
        " */\n",
        "\n",
        "__global__ void doubleElements(int *a, int N)\n",
        "{\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i < N) {\n",
        "    a[i] *= 2;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Check all elements have been doubled on the host.\n",
        " */\n",
        "\n",
        "bool checkElementsAreDoubled(int *a, int N)\n",
        "{\n",
        "  for (int i = 0; i < N; ++i) {\n",
        "    if (a[i] != i*2) {\n",
        "      return false;\n",
        "    }\n",
        "  }\n",
        "  return true;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  int N = 100;\n",
        "  int *a;\n",
        "  size_t size = N * sizeof(int);\n",
        "  \n",
        "  cudaMallocManaged(&a, size); //allocate space for pointer a\n",
        "  init<<<1,1>>>(a, N);         //initialize a pointer a\n",
        "\n",
        "  size_t threads_per_block = 10;\n",
        "  size_t number_of_blocks = 10;\n",
        "\n",
        "  doubleElements<<<number_of_blocks, threads_per_block>>>(a, N);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  bool areDoubled = checkElementsAreDoubled(a, N);\n",
        "  printf(\"All elements were doubled? %s\\n\", areDoubled ? \"TRUE\" : \"FALSE\");\n",
        "\n",
        "  cudaFree(a); //Free memory on GPU\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All elements were doubled? TRUE\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEBqoSy-i5vD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "627c891a-24a5-4ae4-b482-d1c30327c00d"
      },
      "source": [
        "%%cu\n",
        "#include <cstdio>\n",
        "\n",
        "void init(int *a, int N)\n",
        "{\n",
        "  for (int i = 0; i < N; ++i) {\n",
        "    a[i] = i;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * In the current application, 'N' is larger than the grid.\n",
        " * Refactor this kernel to use a grid-stride loop in order that\n",
        " * each parallel thread work on more than one element of the array.\n",
        " */\n",
        "\n",
        "__global__\n",
        "void doubleElements(int *a, int N)\n",
        "{\n",
        "  int indexWithinTheGrid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int gridStride = gridDim.x * blockDim.x;\n",
        "  for (int i = indexWithinTheGrid; i < N; i += gridStride)\n",
        "  {\n",
        "    a[i] *= 2;\n",
        "  }  \n",
        "}\n",
        "\n",
        "bool checkElementsAreDoubled(int *a, int N)\n",
        "{\n",
        "  for (int i = 0; i < N; ++i) {\n",
        "    if (a[i] != i*2) {\n",
        "      return false;\n",
        "    }\n",
        "  }\n",
        "  return true;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  /*\n",
        "   * 'N' is greater than the size of the grid (see below).\n",
        "   */\n",
        "\n",
        "  int N = 10000;\n",
        "  int *a;\n",
        "\n",
        "  size_t size = N * sizeof(int);\n",
        "  cudaMallocManaged(&a, size);\n",
        "\n",
        "  init(a, N);\n",
        "\n",
        "  size_t threads_per_block = 256;\n",
        "  size_t number_of_blocks = 32;\n",
        "\n",
        "  doubleElements<<<number_of_blocks, threads_per_block>>>(a, N);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  bool areDoubled = checkElementsAreDoubled(a, N);\n",
        "  printf(\"All elements were doubled? %s\\n\", areDoubled ? \"TRUE\" : \"FALSE\");\n",
        "\n",
        "  cudaFree(a);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All elements were doubled? TRUE\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmA8k2qjqw_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "de22452c-580e-47b2-ae55-dabfd4381ad5"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include \"cuda.h\"\n",
        "\n",
        "/*\n",
        " * Host function to initialize vector elements. This function\n",
        " * simply initializes each element to equal its index in the\n",
        " * vector.\n",
        " */\n",
        "\n",
        "void initWith(float num, float *a, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; ++i) {\n",
        "    a[i] = num;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Device kernel stores into 'result' the sum of each\n",
        " * same-indexed value of 'a' and 'b'.\n",
        " */\n",
        "\n",
        "__global__\n",
        "void addVectorsInto(float *result, float *a, float *b, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride) {\n",
        "    result[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Host function to confirm values in 'vector'. This function\n",
        " * assumes all values are the same 'target' value.\n",
        " */\n",
        "\n",
        "void checkElementsAre(float target, float *vector, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++) {\n",
        "    if(vector[i] != target)\n",
        "    {\n",
        "      printf(\"FAIL: vector[%d] - %0.0f does not equal %0.0f\\n\", i, vector[i], target);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "  printf(\"Success! All values calculated correctly.\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 2<<24;\n",
        "  size_t size = N * sizeof(float);\n",
        "\n",
        "  float *a, *b, *c;\n",
        "\n",
        "  cudaMallocManaged(&a, size);\n",
        "  cudaMallocManaged(&b, size);\n",
        "  cudaMallocManaged(&c, size);\n",
        "\n",
        "  initWith(3, a, N);\n",
        "  initWith(4, b, N);\n",
        "  initWith(0, c, N);\n",
        "\n",
        "  size_t threadsPerBlock;\n",
        "  size_t numberOfBlocks;\n",
        "\n",
        "  threadsPerBlock = 1;\n",
        "  numberOfBlocks = 1;\n",
        "\n",
        "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  checkElementsAre(7, c, N);\n",
        "\n",
        "  cudaFree(a);\n",
        "  cudaFree(b);\n",
        "  cudaFree(c);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success! All values calculated correctly.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}